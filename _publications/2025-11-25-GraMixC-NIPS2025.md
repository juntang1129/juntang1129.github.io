---
title: "Mixing Configurations for Downstream Prediction"
collection: publications
category: conferences
permalink: /publication/2025-11-25-GraMixC-NIPS2025
excerpt: ''
date: 2025-11-25
venue: '[Proceeding] The 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025)'
citation: '<b>Juntang Wang</b>, Hao Wu, Runkun Guo, Yihan Wang, Dongmian Zou, Shixin Xu (2025). &quot;Mixing Configurations for Downstream Prediction.&quot; <i>The 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025)</i>.'
paperurl: 'https://www.qqgjyx.com/files/p03-GraMixC-NIPS2025.pdf'
---

## Abstract

Humans possess an innate ability to group objects by similarity—a cognitive mechanism that clustering algorithms aim to emulate. Recent advances in community detection have enabled the discovery of configurations—valid hierarchical clusterings across multiple resolution scales—without requiring labeled data. In this paper, we formally characterize these configurations and identify similar emergent structures in register tokens within Vision Transformers. Unlike register tokens, configurations exhibit lower redundancy and eliminate the need for ad hoc selection. They can be learned through unsupervised or self-supervised methods, yet their selection or composition remains specific to the downstream task and input. Building on these insights, we introduce GraMixC, a plug-and-play module that extracts configurations, aligns them using our novel Reverse Merge/Split (RMS) technique, and fuses them via attention heads before forwarding them to any downstream predictor. On the DSNI 16S rRNA cultivation-media prediction task, GraMixC improves the $R^2$ from 0.6 to 0.9 on various methods, setting a new state-of-the-art. We further validate GraMixC across standard tabular benchmarks, where it consistently outperforms single-resolution and static-feature baselines.
